{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from configs import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from dataset import *\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESIZE = 64\n",
    "EPS = 30\n",
    "BSIZE = 64\n",
    "HSIZE = 128\n",
    "LAG = 12\n",
    "SROUTE = SAMPLE_ROUTES[0]\n",
    "SIND = 30\n",
    "LR = 0.001\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locals dataset: train\n",
      " [*] Loaded routes: 1 (0.22s)\n",
      " [*] Has trainable inds: 262262\n",
      " [*] Subset train: 212106\n",
      " [*] Subset in Stop-30: 6079\n",
      "Locals dataset: test\n",
      " [*] Loaded routes: 1 (0.25s)\n",
      " [*] Has trainable inds: 262262\n",
      " [*] Subset test: 50156\n",
      " [*] Subset in Stop-30: 1549\n"
     ]
    }
   ],
   "source": [
    "dset = SingleStop(SROUTE, SIND, 'train', BSIZE, lag=LAG).generator()\n",
    "evalset = SingleStop(SROUTE, SIND, 'test', BSIZE, lag=LAG).generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = None\n",
    "upops = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "kopt, uopt, sch = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 114\n",
      "[E2:30 - B56:94 - T5:12] L4.38      \r"
     ]
    }
   ],
   "source": [
    "from models.Kernel import *\n",
    "\n",
    "def zip_op(t1, t2, op):\n",
    "    ls = [(t1, t2)]\n",
    "    while len(ls):\n",
    "        n1, n2 = ls[0]\n",
    "        ls = ls[1:]\n",
    "        op(n1, n2)\n",
    "        for c1, c2 in zip(n1['ns'], n2.ns):\n",
    "            ls.append((c1, c2))\n",
    "\n",
    "def message(kernels, graph_t):\n",
    "    zip_op(kernels, graph_t, op=lambda kern, node: kern['op'](node))\n",
    "    \n",
    "def update(kernels, graph_t):\n",
    "    zip_op(upops, graph_t, op=lambda up, node: up['op'](node))\n",
    "    \n",
    "def gather_predictions(_node, node):\n",
    "    # end nodes do not hold convolved results, so they are ignored\n",
    "    ls = [(_node._v, node.v)] if len(node.ns) else []\n",
    "    for _nb, nb in zip(_node.ns, node.ns):\n",
    "        ls += gather_predictions(_nb, nb)\n",
    "    return ls\n",
    "\n",
    "losses = []\n",
    "for ei in range(EPS):\n",
    "#     for bi in range(0, len(dset) - BSIZE, BSIZE):\n",
    "#         batch = np.array([dset[bi+jj] for jj in range(BSIZE)])\n",
    "#         # batch x time x seq\n",
    "#         batch = torch.Tensor(batch)\n",
    "    for bi, batch in enumerate(dset):\n",
    "#         assert batch.size()[0] == BSIZE\n",
    "#         assert torch.any (batch != batch)\n",
    "        # batch x time x seq\n",
    "        batch = routeToGraph(\n",
    "            batch, \n",
    "            zero=lambda: torch.zeros(BSIZE, HSIZE), \n",
    "            device=device)\n",
    "\n",
    "        states = batch[0] # will be used to hold iterated values\n",
    "        if kernels is None:\n",
    "            (kernels,), kps = inst_tree(\n",
    "                lambda node: Kernel(insize=1 + len(node.ns), hsize=HSIZE).to(device), \n",
    "                [states], device=device)\n",
    "            kopt = optim.SGD(kps, lr=LR)\n",
    "            print('Params: %d' % len(params))\n",
    "            (upops,), ups = inst_tree(\n",
    "                lambda _: Update(hsize=HSIZE).to(device), \n",
    "                [states], device=device)\n",
    "            uopt = optim.SGD(ups, lr=LR)\n",
    "            sch = optim.lr_scheduler.StepLR(\n",
    "                kps + ups, \n",
    "                step_size=15, \n",
    "                gamma=0.1)\n",
    "\n",
    "        # initial iteration\n",
    "        _ = message(kernels, states)\n",
    "        _ = update(upops, states)\n",
    "\n",
    "        def fit(_ys, ys, retain=True):\n",
    "            kopt.zero_grad()\n",
    "            uopt.zero_grad()\n",
    "            loss = criterion(ys, _ys)\n",
    "\n",
    "            loss.backward(retain_graph=retain)\n",
    "            kopt.step()\n",
    "            uopt.step()\n",
    "            return loss\n",
    "\n",
    "        for ti, graph_t in enumerate(batch[1:]):\n",
    "            # compute loss\n",
    "            _ys, ys = zip(*gather_predictions(graph_t, states))\n",
    "            _ys, ys = torch.cat(_ys, dim=1), torch.cat(ys, dim=1)\n",
    "\n",
    "            loss = fit(_ys, ys, True)\n",
    "\n",
    "            # iterate\n",
    "            _ = message(kernels, states)\n",
    "            _ = update(upops, states)\n",
    "\n",
    "            sys.stdout.write('[E%d:%d - B%d:%d - T%d:%d] L%.2f    \\r' % (\n",
    "                ei + 1, EPS,\n",
    "                bi, len(dset), ti+2, len(batch),\n",
    "                loss.item()))\n",
    "            losses.append(loss.item())\n",
    "        fit(_ys, ys, False) # don't forget to fit the last iteration\n",
    "\n",
    "        sys.stdout.flush()\n",
    "    sch.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(losses)\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ys, ys = zip(*gather_predictions(graph_t, states))\n",
    "_ys, ys = torch.cat(_ys, dim=1), torch.cat(ys, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    print(tonpy(_ys)[ii].shape)\n",
    "    plt.plot(tonpy(_ys)[ii])\n",
    "    plt.plot(tonpy(ys)[ii])\n",
    "    plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
